{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 今天是2019年9月28日，今天世界上又多了一名AI工程师 :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`各位同学大家好，欢迎各位开始学习我们的人工智能课程。这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。根据往期同学的实际反馈，我们课程的完结之后 能力能够超过80%的计算机人工智能/深度学习方向的硕士生的能力。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 请回答以下问题\n",
    "\n",
    "回答以下问题，并将问题发送至 minchiuan.gao@gmail.com 中：\n",
    "```\n",
    "    2.1. what do you want to acquire in this course？\n",
    "    2.2. what problems do you want to solve？\n",
    "    2.3. what’s the advantages you have to finish you goal?\n",
    "    2.4. what’s the disadvantages you need to overcome to finish you goal?\n",
    "    2.5. How will you plan to study in this course period?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 如何提交\n",
    "代码 + 此 jupyter 相关，提交至自己的 github 中(**所以请务必把GitHub按照班主任要求录入在Trello中**)；\n",
    "第2问，请提交至minchiuan.gao@gmail.com邮箱。\n",
    "#### 4. 作业截止时间\n",
    "此次作业截止时间为 2019.10.8日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: chat bot( customer service), auto-drive car,  IOT, AI medical support tool "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Github for tracking a project and to colloabrate with other team members if have ; it is also a great tool to share your ideas/codes with others. \n",
    "We use jupyter notebook because it is an interactive tool to visulize the results and more organized and presentable way to express our ideas.\n",
    "I use VS Code now instead of Pycharm ,  because vs code is free. But i think both of them are very powerful to have mutiple functions into one IDE, such as debug, develop a large project with multiple parts of code scripts and testing your code; ...... integrate terminal text editor ( vi /vim) but with much more powerful linting checking ( syntax check) .. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:A probability model is a mathematical representation of a random phenomenon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: predict stock price;  to calculate a random event occur chance; rolling a die"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  A language model is a probability distribution over entire sentences or texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Automatic speech/entity recognition; chat bot; Machine translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Each individual word is a token, and count/total_words ≈ probability; Unigram probability of sentence = product of probabilities of individual words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: disadvantage is that too simple, which totally ignore the the order of words in a sentence ; advantages: easy to implement and interpreting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Probability of a word occurence depends only on previous word, ( markov chain assumption)\n",
    "P(wi | wi-1) =count(wi-1,wi) / count(wi-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1569578233461&di=4adfa7597fb380e7cc0e67190bbd7605&imgtype=0&src=http%3A%2F%2Fs1.sinaimg.cn%2Flarge%2F006eYYfyzy76cmpG3Yb1f)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:08:41.553812Z",
     "start_time": "2019-10-13T03:08:41.551141Z"
    }
   },
   "outputs": [],
   "source": [
    "student_grade = '''\n",
    "student_grade = student took exam of the course and got grade .\n",
    "course = Math | Music | Biology | Data_mining | Physics| Economics\n",
    "exam = quiz | take-home-challenge | mid-term | final-exam\n",
    "student = Jimmy | Mary | Grace | Mat | Dave | Nick\n",
    "grade = A+ | A | B | C | D | F \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:08:42.589103Z",
     "start_time": "2019-10-13T03:08:42.586451Z"
    }
   },
   "outputs": [],
   "source": [
    "take_away_food = '''\n",
    "take_away_food = someone has made the order order_num with amount_value which will be deliveried within delivery_time .\n",
    "order_num = #1001 | #1002 | #1003 | #1004 | #1005\n",
    "amount_value = $15.15 | $20.23| $33.69 | $24.34 | $50.55\n",
    "someone = Sean | Linda | Menga | Jack | Jason\n",
    "delivery_time  = 20 minutes | 50 minutes | an hour | 35 minutes | 45 minutes\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:08:43.285872Z",
     "start_time": "2019-10-13T03:08:43.282226Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_grammar(grammar_str, split='=', line_split='\\n'):\n",
    "    grammar = {}\n",
    "    for line in grammar_str.split(line_split):\n",
    "        if not line.strip(): continue\n",
    "        exp, stmt = line.split(split)\n",
    "        grammar[exp.strip()] = [s.split() for s in stmt.split('|')]\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:08:43.642903Z",
     "start_time": "2019-10-13T03:08:43.638120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'student_grade': [['student',\n",
       "   'took',\n",
       "   'exam',\n",
       "   'of',\n",
       "   'the',\n",
       "   'course',\n",
       "   'and',\n",
       "   'got',\n",
       "   'grade',\n",
       "   '.']],\n",
       " 'course': [['Math'],\n",
       "  ['Music'],\n",
       "  ['Biology'],\n",
       "  ['Data_mining'],\n",
       "  ['Physics'],\n",
       "  ['Economics']],\n",
       " 'exam': [['quiz'], ['take-home-challenge'], ['mid-term'], ['final-exam']],\n",
       " 'student': [['Jimmy'], ['Mary'], ['Grace'], ['Mat'], ['Dave'], ['Nick']],\n",
       " 'grade': [['A+'], ['A'], ['B'], ['C'], ['D'], ['F']]}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_grammar(student_grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:08:43.999802Z",
     "start_time": "2019-10-13T03:08:43.993584Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_grammar(grammar_str, split='=', line_split='\\n'):\n",
    "    grammar = {}\n",
    "    for line in grammar_str.split(line_split):\n",
    "        if not line.strip(): continue\n",
    "        exp, stmt = line.split(split)\n",
    "        grammar[exp.strip()] = [s.split() for s in stmt.split('|')]\n",
    "    return grammar\n",
    "\n",
    "def generate(gram, target):\n",
    "    if target not in gram:\n",
    "        return target # means target is a terminal expression\n",
    "    expaned = [generate(gram, t) for t in random.choice(gram[target])]\n",
    "    \n",
    "    return ' '.join([e if e != '/n' else '\\n' for e in expaned if e != 'null'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:08:45.330961Z",
     "start_time": "2019-10-13T03:08:45.327313Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_n(gram,n, target):\n",
    "    # you code here \n",
    "    for i in range(n):\n",
    "        print(generate(gram= gram, target=target))\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:08:45.773790Z",
     "start_time": "2019-10-13T03:08:45.770261Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grace took take-home-challenge of the Economics and got A+ .\n",
      "Dave took quiz of the Math and got C .\n",
      "Jimmy took mid-term of the Data_mining and got D .\n",
      "Grace took mid-term of the Economics and got B .\n",
      "Jimmy took take-home-challenge of the Biology and got D .\n",
      "Mat took quiz of the Math and got C .\n",
      "Dave took final-exam of the Data_mining and got A+ .\n",
      "Grace took take-home-challenge of the Data_mining and got A .\n",
      "Jimmy took take-home-challenge of the Economics and got A .\n",
      "Dave took quiz of the Music and got F .\n",
      "Jimmy took mid-term of the Biology and got B .\n",
      "Mary took mid-term of the Physics and got A+ .\n"
     ]
    }
   ],
   "source": [
    "generate_n(gram=create_grammar(student_grade), target='student_grade',n=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:09:40.004699Z",
     "start_time": "2019-10-13T03:09:40.000458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menga has made the order #1003 with $24.34 which will be deliveried within 35 minutes .\n",
      "Menga has made the order #1002 with $50.55 which will be deliveried within 50 minutes .\n",
      "Jack has made the order #1004 with $15.15 which will be deliveried within 50 minutes .\n",
      "Menga has made the order #1002 with $50.55 which will be deliveried within an hour .\n",
      "Sean has made the order #1003 with $20.23 which will be deliveried within 20 minutes .\n"
     ]
    }
   ],
   "source": [
    "generate_n(gram=create_grammar(take_away_food), target='take_away_food',n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:01:04.991054Z",
     "start_time": "2019-10-13T03:01:04.987835Z"
    }
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T02:45:19.360104Z",
     "start_time": "2019-10-13T02:45:19.356468Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = '/Users/gyr/Documents/NLP/nlp_demo/movie_comments.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T02:45:21.418330Z",
     "start_time": "2019-10-13T02:45:21.410633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1: id,link,name,comment,star\n",
      "\n",
      "Line 2: 1,https://movie.douban.com/subject/26363254/,战狼2,吴京意淫到了脑残的地步，看了恶心想吐,1\n",
      "\n",
      "Line 3: 2,https://movie.douban.com/subject/26363254/,战狼2,首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮番上场，视物理逻辑于不顾，不得不说有钱真好，随意胡闹,2\n",
      "\n",
      "Line 4: 3,https://movie.douban.com/subject/26363254/,战狼2,吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋律，为了煽情而煽情，让人觉得他是个大做作、大谎言家。（7.29更新）片子整体不如湄公河行动，1.整体不够流畅，编剧有毒，台词尴尬；2.刻意做作的主旋律煽情显得如此不合时宜而又多余。,2\n",
      "\n",
      "Line 5: 4,https://movie.douban.com/subject/26363254/,战狼2,凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。,4\n",
      "\n",
      "Line 6: 5,https://movie.douban.com/subject/26363254/,战狼2,中二得很,1\n",
      "\n",
      "Line 7: 6,https://movie.douban.com/subject/26363254/,战狼2,“犯我中华者，虽远必诛”，吴京比这句话还要意淫一百倍。,1\n",
      "\n",
      "Line 8: 7,https://movie.douban.com/subject/26363254/,战狼2,脑子是个好东西，希望编剧们都能有。,2\n",
      "\n",
      "Line 9: 8,https://movie.douban.com/subject/26363254/,战狼2,三星半，实打实的7分。第一集在爱国主旋律内部做着各种置换与较劲，但第二集才真正显露吴京的野心，他终于抛弃李忠志了，新增外来班底让硬件实力有机会和国际接轨，开篇水下长镜头和诸如铁丝网拦截RPG弹头的细节设计都让国产动作片重新封顶，在理念上，它甚至做到《绣春刀2》最想做到的那部分。,4\n",
      "\n",
      "Line 10: 9,https://movie.douban.com/subject/26363254/,战狼2,开篇长镜头惊险大气引人入胜 结合了水平不俗的快剪下实打实的真刀真枪 让人不禁热血沸腾 特别弹簧床架挡炸弹 空手接碎玻璃 弹匣割喉等帅得飞起！就算前半段铺垫节奏散漫主角光环开太大等也不怕 作为一个中国人 两个小时弥漫着中国强大得不可侵犯的氛围 还是让那颗民族自豪心砰砰砰跳个不停。,4\n",
      "\n",
      "Line 11: 10,https://movie.douban.com/subject/26363254/,战狼2,15/100吴京的冷峰在这部里即像成龙，又像杰森斯坦森，但体制外的同类型电影，主角总是代表个人，无能的政府需要求助于这些英雄才能解决难题，体现的是个人的价值，所以主旋律照抄这种模式实际上是有问题的。我们以前嘲笑个人英雄主义，却没想到捆绑爱国主义的全能战士更加难以下咽。,1\n",
      "\n",
      "Line 12: 11,https://movie.douban.com/subject/26363254/,战狼2,犯我中华者虽远必诛，是有多无脑才信这句话。,1\n",
      "\n",
      "Line 13: 12,https://movie.douban.com/subject/26363254/,战狼2,这部戏让人看的热血沸腾，对吴京路转粉，最后的彩蛋，让我们没有理由不期待下一部。,4\n",
      "\n",
      "Line 14: 13,https://movie.douban.com/subject/26363254/,战狼2,假嗨，特别恶心的电影。,1\n",
      "\n",
      "Line 15: 14,https://movie.douban.com/subject/26363254/,战狼2,有几处情节设置过于尴尬，彰显国家自豪感的部分稍显突兀。,2\n",
      "\n",
      "Line 16: 15,https://movie.douban.com/subject/26363254/,战狼2,就是一部爽片，打戏挺燃，但是故事一般。达康书记不合适这个角色，赵东来倒是很合适。张瀚太太太违和了，分分钟穿越回偶像剧。,2\n",
      "\n",
      "Line 17: 16,https://movie.douban.com/subject/26363254/,战狼2,赵东来：达康书记，我们接到在非洲卧底的冷锋报告，丁义珍现在非洲，我们请求抓捕。李达康：东来，这件事先不要声张，特别是别让省厅知道，就你和我一起去非洲，加上冷锋同志，三人逮捕丁义珍。这次行就叫战狼2吧,5\n",
      "\n",
      "Line 18: 17,https://movie.douban.com/subject/26363254/,战狼2,下一部拍喜剧吧，整个片子真感觉挺搞笑的,2\n",
      "\n",
      "Line 19: 18,https://movie.douban.com/subject/26363254/,战狼2,《战狼2》里吴京这么能打，他打得过徐晓冬么？,3\n",
      "\n",
      "Line 20: 19,https://movie.douban.com/subject/26363254/,战狼2,心往一处想，劲往一处使，就能实现我们的梦想。看吧，比第一部好太多了。谢谢美队的动作指导。,3\n",
      "\n",
      "Line 21: 20,https://movie.douban.com/subject/26363254/,战狼2,这都能火。是我没见识！,2\n",
      "\n",
      "Line 22: 21,https://movie.douban.com/subject/26363254/,战狼2,开头的水下长对决戏可算华语电影的顶尖存在；驱逐舰、导弹和坦克在商业片里这么狂用也是了得；镜头运用和笑点插入都很好莱坞爆米花，不功不过；从头打到尾是真拼，虽然镜头也有略乱时；因为没啥期望值，所以被吴京的野心吓了一跳；吴刚、于谦和丁海峰老三位像炖烂熟的牛筋，嚼着就舒服。,4\n",
      "\n",
      "Line 23: 22,https://movie.douban.com/subject/26363254/,战狼2,很用心啊吴京导演，小看你了，确实在导演上下功夫了拉片子了，知道借鉴是好的。至于大家比较反感的小粉红情绪我觉得那些桥段都是主旋律必备啊是稍微有一点过但还可以接受。最好的地方是吴京节奏掌握得很好，知道张弛有度，这点很难得。,4\n",
      "\n",
      "Line 24: 23,https://movie.douban.com/subject/26363254/,战狼2,犯我中华者虽远必诛，这句话一直在我脑子里回响,4\n",
      "\n",
      "Line 25: 24,https://movie.douban.com/subject/26363254/,战狼2,片头海里那场动作戏看完就呆不下去了，太假太做作，提前离场。,1\n",
      "\n",
      "Line 26: 25,https://movie.douban.com/subject/26363254/,战狼2,好看，这部戏让人看的热血沸腾，打戏挺燃的，吴京演技棒呆了,4\n",
      "\n",
      "Line 27: 26,https://movie.douban.com/subject/26363254/,战狼2,符合“有钱了续集反而拍更差”这一放之四海而皆准的规律，场面越做越大，然而伴随着各种动作场面和特效场面的升级，这一部的叙事反而变得非常凌乱。格局颇大，想拍成《黑鹰坠落》，结果撑死最多也只是官方主旋律版的《敢死队》。吴京确实有野心，但论自我角色定位能力远不如同是动作演员出身的甄子丹。,2\n",
      "\n",
      "Line 28: 27,https://movie.douban.com/subject/26363254/,战狼2,说喜欢这部片子的人不是装傻就是真傻，要不是真的没有别的可看肯定是不会选这部的，直男癌到令人发指，所有剧情走向也完全是九十年代那套照搬，审美这件事儿真不是一时半会儿能培养出来的。,2\n",
      "\n",
      "Line 29: 28,https://movie.douban.com/subject/26363254/,战狼2,整部电影延续1的风格，热血。场面比1来的要大，打戏动作不错，吴京挺适合演军人的，电影之前的中国梦片段他都念的劲儿劲儿的。整体来说还不错，不过张翰太违和了，一出来就一股雷阵雨的画风。,4\n",
      "\n",
      "Line 30: 29,https://movie.douban.com/subject/26363254/,战狼2,目瞪狗呆！太瘠薄好看了！中国人牛b就是硬道理！隔壁建军大爷都没你们爱国,1\n",
      "\n",
      "Line 31: 30,https://movie.douban.com/subject/26363254/,战狼2,《战狼2》的动作场景和战斗装备全线升级，热血的打斗动作从头打到尾。《战狼2》游走在电影审查红线的边界和政治安全的缝隙，是部延续了第一部极具煽动爱国情绪的国产动作大片。如此制作精良的影片，还请多来一点。,4\n",
      "\n",
      "Line 32: 31,https://movie.douban.com/subject/26363254/,战狼2,电影用的胶卷挺差的，故事过度也差，地方部队还没太多展示就死去，反正各种问题。但就是能吸引人看下去，就冲这，为什么要这么鄙视敢想敢去开拓的人，不允许他们再去拍，直到能有更好的人，拍出更棒的更出彩的电影来呢？,3\n",
      "\n",
      "Line 33: 32,https://movie.douban.com/subject/26363254/,战狼2,火爆的场面拍出了好莱坞大片的感觉，本片必将燃爆暑期,4\n",
      "\n",
      "Line 34: 33,https://movie.douban.com/subject/26363254/,战狼2,吴京厉害了，身为武打演员，能拍到这么高标准的大场面的枪战戏，为你点赞。热血男儿，荷尔蒙爆发！,5\n",
      "\n",
      "Line 35: 34,https://movie.douban.com/subject/26363254/,战狼2,能给0星么，好恶心啊,1\n",
      "\n",
      "Line 36: 35,https://movie.douban.com/subject/26363254/,战狼2,《血战钢锯岭》中国人也会觉得好看，因为它歌颂的宗教情怀是超越政权的；但当你只想歌颂一个政权时，很明显就低了一个层次，甚至充满了现实乃至投机的考量，高下立见,3\n",
      "\n",
      "Line 37: 36,https://movie.douban.com/subject/26363254/,战狼2,请问吴京脑残，弹簧床能挡火箭炮吗？,1\n",
      "\n",
      "Line 38: 37,https://movie.douban.com/subject/26363254/,战狼2,上一部是傲气雄鹰，这一部是第一滴血4。吴京算是国内导演对类型片感觉比较准的，作为动作片钱都花在有效地方，整体火爆流畅，有大片气魄，创作上也足够真诚。人物设计也都不错，连张翰都很可爱了。如果吴京不像当年甄子丹那样一时膨胀、在银幕上独占聚光灯，肯定可以走得更远。,4\n",
      "\n",
      "Line 39: 38,https://movie.douban.com/subject/26363254/,战狼2,扪心自问这种电影真没法评价，全片靠动作戏撑完，文戏都是扯淡，女主角毫无存在的必要，故事不需要逻辑只要主角开挂，但牛逼之处在于全片都透露着极强烈的爱国主义光环和意识形态枷锁，在祖国面前，一切反动派都是纸老虎，所以战狼一个人开挂团灭一个连都是合情合理的，动作戏还不错，挺用心，两星鼓励,2\n",
      "\n",
      "Line 40: 39,https://movie.douban.com/subject/26363254/,战狼2,扪心自问这种电影真没法评价，全片靠动作戏撑完，文戏都是扯淡，女主角毫无存在的必要，故事不需要逻辑只要主角开挂，但牛逼之处在于全片都透露着极强烈的爱国主义光环和意识形态枷锁，在祖国面前，一切反动派都是纸老虎，所以战狼一个人开挂团灭一个连都是合情合理的，动作戏还不错，挺用心，两星鼓励,2\n",
      "\n",
      "Line 41: 40,https://movie.douban.com/subject/26363254/,战狼2,两星给打戏，其他一般般，没啥看点，还有点尴尬？,2\n",
      "\n",
      "Line 42: 41,https://movie.douban.com/subject/26363254/,战狼2,太尴尬了！！！！手接炸弹！！哈哈哈！！！从张翰出来之后，我就想炸了他！！,1\n",
      "\n",
      "Line 43: 42,https://movie.douban.com/subject/26363254/,战狼2,翻了一下我给第一部的评价是四星，当时觉得挺燃的，这部其实在完成度上更接近好莱坞的制作了，每个步骤每个人物的走向都很顺滑，没有任何出人意料的地方。只给三星是因为，看看最近现实世界的一切，抱歉我在影院里燃不起来，只是觉得一切都很魔幻，当然开头的强拆是最有现实感的一幕了。,3\n",
      "\n",
      "Line 44: 43,https://movie.douban.com/subject/26363254/,战狼2,太喜欢《战狼2》开场6分钟长镜头的水下搏斗戏了！从来没有在其它任何一部电影里看到过，因为拍摄难度真的不一般，同时还对演员有各种技能方面的要求。看完片子回来搜了下，被吴京会游泳、潜水、滑雪、开飞机、开坦克、射击等各项技能，还特意去特种部队当过18个月兵…真的很佩服这样的电影人！,5\n",
      "\n",
      "Line 45: 44,https://movie.douban.com/subject/26363254/,战狼2,3星半。1.电影结束有掌声出现，近期少见。2.一粒爱国主义大补丸，有人吃的开心，有人觉得补大了。3.从头打到尾，从白打到黑。4.从片头字幕到影片细节，完全展现了吴京作为一个超级直男的糙和猛。主角光环媲美终结者。5.达康书记无亮点，张翰变谐星。6.3D？？？7.导演的掌控能力逼近Hold不住的边缘。,3\n",
      "\n",
      "Line 46: 45,https://movie.douban.com/subject/26363254/,战狼2,打戏非常带感，燃爆了，拳拳到肉，看得超爽！,4\n",
      "\n",
      "Line 47: 46,https://movie.douban.com/subject/26363254/,战狼2,吴京确实很聪明，很鸡贼。在一面大旗下呈现了一出重工业娱乐电影。他一直调控着说教和娱乐的比例，娱乐多了，尺度不被允许，说教多了，大众不接纳，比例把握非常微妙。这其中还是有一些“奇侠”化的内容，比如用玻璃碴子当飞镖杀敌一类，只不过被遮盖掉了。“老爹”演过美剧《搏击王国》，力荐那部美剧,3\n",
      "\n",
      "Line 48: 47,https://movie.douban.com/subject/26363254/,战狼2,作为主旋律影片为啥用《奇异恩典》配乐，画内镜头还是中国军人……,3\n",
      "\n",
      "Line 49: 48,https://movie.douban.com/subject/26363254/,战狼2,男生看这部电影的话，应该会很喜欢，因为很刺激肾上腺素，如果是女生，冷锋对龙小云的感情也会十分打动你，真的！,5\n",
      "\n",
      "Line 50: 49,https://movie.douban.com/subject/26363254/,战狼2,无脑动作片，模仿许多好莱坞大场面再想怎么玩怎么玩一股脑堆，槽点多到炸，几位主角血厚到科幻级别，吴京重复演满血，红血，中毒，极速回血，爆种打通全场...确实很拼但片子太过投机取巧，炸穿银幕连迈克尔贝都不受待见了，国片还前仆后继炸不停，故事不好看堆再多大场面大爆炸假high瞎燃也没用。5/10,2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(corpus) as f:\n",
    "    line = f.readline()\n",
    "    cnt = 1\n",
    "    subset_text_50 = []\n",
    "    while cnt <= 50:\n",
    "        print(f\"Line {cnt}: {line}\")\n",
    "        subset_text_50.append(line)\n",
    "        line = f.readline()\n",
    "        cnt += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T02:48:25.078251Z",
     "start_time": "2019-10-13T02:48:24.513057Z"
    }
   },
   "outputs": [],
   "source": [
    "comments_df = pd.read_csv(corpus,usecols=['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T02:52:54.692686Z",
     "start_time": "2019-10-13T02:52:54.021969Z"
    }
   },
   "outputs": [],
   "source": [
    "comment_by_line = [re.sub(r'[^\\w]','', c) for c in comments_df.comment if isinstance(c, str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T02:59:04.590006Z",
     "start_time": "2019-10-13T02:59:04.558774Z"
    }
   },
   "outputs": [],
   "source": [
    "FILE = ''.join(comment_by_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T02:59:13.070766Z",
     "start_time": "2019-10-13T02:59:13.066894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'吴京意淫到了脑残的地步看了恶心想吐首映礼看的太恐怖了这个电影不讲道理的完全就是吴京在实现他这个小粉红'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:55:48.466415Z",
     "start_time": "2019-10-13T03:55:48.460391Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_by_pro(text_corpus, length=20):\n",
    "    return ''.join(random.sample(text_corpus, length))\n",
    "\n",
    "def tokenlize(file_text):\n",
    "    split_tokens = jieba.cut(file_text)\n",
    "    \n",
    "    return [token.strip() for token in split_tokens]\n",
    "\n",
    "\n",
    "def get_n_gram_count(word, wc):\n",
    "    if word in wc: return wc[word]\n",
    "    else:\n",
    "        return wc.most_common()[-1][-1]\n",
    "    \n",
    "def two_gram_model(sentence):\n",
    "    tokens = tokenlize(sentence)\n",
    "    total_prob = 1\n",
    "    for i in range(len(tokens)-1):\n",
    "        word = tokens[i]\n",
    "        next_word = tokens[i+1]\n",
    "        _2_wc = get_n_gram_count(word+next_word,Counter(_2_gram_words))\n",
    "        _1_wc = get_n_gram_count(next_word,word_frequency)\n",
    "    \n",
    "        next_token_prob = _2_wc/_1_wc\n",
    "        total_prob *= next_token_prob\n",
    "    return total_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:02:44.356304Z",
     "start_time": "2019-10-13T03:01:48.781608Z"
    }
   },
   "outputs": [],
   "source": [
    "TOKENS = tokenlize(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:04:17.032251Z",
     "start_time": "2019-10-13T03:04:17.028726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4487032"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TOKENS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:04:25.728068Z",
     "start_time": "2019-10-13T03:04:25.723565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京', '意淫', '到', '了', '脑残', '的', '地步', '看', '了', '恶心']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:19:31.555046Z",
     "start_time": "2019-10-13T03:19:31.551659Z"
    }
   },
   "outputs": [],
   "source": [
    "# most_com_sample = Counter(generate_by_pro(FILE, length=100)).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:55:52.796909Z",
     "start_time": "2019-10-13T03:55:52.302118Z"
    }
   },
   "outputs": [],
   "source": [
    "word_frequency = Counter(TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:55:53.852970Z",
     "start_time": "2019-10-13T03:55:52.890648Z"
    }
   },
   "outputs": [],
   "source": [
    "_2_gram_words = [TOKENS[i] + TOKENS[i+1] for i in range(len(TOKENS) -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:55:53.959777Z",
     "start_time": "2019-10-13T03:55:53.955853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京意淫', '意淫到', '到了', '了脑残', '脑残的', '的地步', '地步看', '看了', '了恶心', '恶心想']"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_2_gram_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:55:55.894388Z",
     "start_time": "2019-10-13T03:55:54.636178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4538"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_gram_count('看了',Counter(_2_gram_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T03:55:56.437432Z",
     "start_time": "2019-10-13T03:55:55.897194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_gram_count('吴京',Counter(TOKENS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T04:06:28.571241Z",
     "start_time": "2019-10-13T04:06:28.566694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'凭良心说好看到不像战狼1的续集完虐湄公河行动'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_by_line[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T04:06:53.066098Z",
     "start_time": "2019-10-13T04:06:42.670071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0078466457984741e-21"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_gram_model(comment_by_line[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([1, 3, 5, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数接受一个参数key，这个参数接受一个函数作为输入，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第0个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0), (1, 4), (4, 4), (2, 5)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (1, 4), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序, 但是是递减的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def generate_best(): \n",
    "    # you code here\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: mqgao@kaikeba.com 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
